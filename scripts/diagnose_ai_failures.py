#!/usr/bin/env python3
"""
AI Enhancement å¤±è´¥è¯Šæ–­å·¥å…·

ç”¨äºåˆ†æä¸ºä»€ä¹ˆAIå¢å¼ºä¼šå¤±è´¥ï¼Œæä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
"""

import sys
from pathlib import Path
from collections import defaultdict

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from codeindex.config import Config
from codeindex.scanner import scan_directory
from codeindex.parallel import parse_files_parallel
from codeindex.writer import (
    format_files_for_prompt,
    format_symbols_for_prompt,
    format_imports_for_prompt,
)
from codeindex.invoker import format_prompt
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

console = Console()


def analyze_directory_prompt_size(dir_path: Path, config: Config) -> dict:
    """åˆ†æå•ä¸ªç›®å½•çš„promptå¤§å°"""

    console.print(f"[dim]Analyzing {dir_path}...[/dim]")

    # Scan directory
    result = scan_directory(dir_path, config, recursive=True)

    if not result.files:
        return {
            "files": 0,
            "symbols": 0,
            "prompt_size": 0,
            "status": "empty",
        }

    # Parse files
    parse_results = parse_files_parallel(result.files, config, quiet=True)

    # Calculate sizes
    file_count = len(parse_results)
    symbol_count = sum(len(r.symbols) for r in parse_results)
    import_count = sum(len(r.imports) for r in parse_results)

    # Generate prompt components
    files_info = format_files_for_prompt(parse_results)
    symbols_info = format_symbols_for_prompt(parse_results)
    imports_info = format_imports_for_prompt(parse_results)
    prompt = format_prompt(dir_path, files_info, symbols_info, imports_info)

    prompt_size = len(prompt.encode("utf-8"))

    # Determine status
    if prompt_size > 200 * 1024:  # 200KB
        status = "too_large"
    elif prompt_size > 100 * 1024:  # 100KB
        status = "risky"
    elif prompt_size > 50 * 1024:  # 50KB
        status = "large"
    else:
        status = "ok"

    return {
        "files": file_count,
        "symbols": symbol_count,
        "imports": import_count,
        "files_info_size": len(files_info),
        "symbols_info_size": len(symbols_info),
        "imports_info_size": len(imports_info),
        "prompt_size": prompt_size,
        "status": status,
        "parse_results": parse_results,  # ç”¨äºè¯¦ç»†åˆ†æ
    }


def estimate_timeout_needed(analysis: dict) -> int:
    """ä¼°ç®—éœ€è¦çš„è¶…æ—¶æ—¶é—´"""
    base_timeout = 60

    file_count = analysis["files"]
    symbol_count = analysis["symbols"]

    # æ¯10ä¸ªæ–‡ä»¶+30ç§’
    file_factor = (file_count // 10) * 30

    # æ¯100ä¸ªç¬¦å·+20ç§’
    symbol_factor = (symbol_count // 100) * 20

    # æœ€å¤§5åˆ†é’Ÿ
    return min(base_timeout + file_factor + symbol_factor, 300)


def suggest_improvements(analysis: dict, timeout_config: int) -> list[str]:
    """æ ¹æ®åˆ†æç»“æœæä¾›æ”¹è¿›å»ºè®®"""
    suggestions = []

    # æ£€æŸ¥promptå¤§å°
    prompt_kb = analysis["prompt_size"] / 1024
    if analysis["status"] == "too_large":
        suggestions.append(
            f"ğŸš¨ CRITICAL: Promptå¤ªå¤§ ({prompt_kb:.0f}KB)ï¼Œå¿…é¡»å‹ç¼©ï¼š\n"
            f"   - å¯ç”¨smart prompt compressionï¼ˆå¾…å®ç°ï¼‰\n"
            f"   - æˆ–è€…splitç›®å½•ä¸ºå¤šä¸ªå­ç›®å½•"
        )
    elif analysis["status"] == "risky":
        suggestions.append(
            f"âš ï¸  Promptè¾ƒå¤§ ({prompt_kb:.0f}KB)ï¼Œå¯èƒ½ä¸ç¨³å®šï¼š\n"
            f"   - å»ºè®®å¯ç”¨prompt compression\n"
            f"   - å¢åŠ timeoutåˆ° {estimate_timeout_needed(analysis)}ç§’"
        )
    elif analysis["status"] == "large":
        suggestions.append(
            f"â„¹ï¸  Promptä¸­ç­‰ ({prompt_kb:.0f}KB)ï¼Œä½†å»ºè®®ä¼˜åŒ–ï¼š\n"
            f"   - è€ƒè™‘å¯ç”¨compressionä»¥æå‡é€Ÿåº¦"
        )

    # æ£€æŸ¥è¶…æ—¶é…ç½®
    estimated_timeout = estimate_timeout_needed(analysis)
    if estimated_timeout > timeout_config:
        suggestions.append(
            f"â±  å»ºè®®å¢åŠ timeoutï¼š{timeout_config}ç§’ â†’ {estimated_timeout}ç§’"
        )

    # æ£€æŸ¥ç¬¦å·æ•°é‡
    if analysis["symbols"] > 500:
        suggestions.append(
            f"ğŸ“Š ç¬¦å·æ•°é‡å¾ˆå¤§ ({analysis['symbols']}ä¸ª)ï¼Œå»ºè®®ï¼š\n"
            f"   - æ£€æŸ¥æ˜¯å¦æœ‰å¤§é‡get*/set*æ–¹æ³•å¯ä»¥æ’é™¤\n"
            f"   - è€ƒè™‘ä½¿ç”¨ç¬¦å·åˆ†ç»„æ‘˜è¦ï¼ˆå¾…å®ç°ï¼‰"
        )

    # æ£€æŸ¥æ–‡ä»¶æ•°é‡
    if analysis["files"] > 50:
        suggestions.append(
            f"ğŸ“ æ–‡ä»¶æ•°é‡å¾ˆå¤§ ({analysis['files']}ä¸ª)ï¼Œå»ºè®®ï¼š\n"
            f"   - è€ƒè™‘æŒ‰å­ç›®å½•è¿›ä¸€æ­¥ç»„ç»‡ä»£ç \n"
            f"   - æˆ–ä½¿ç”¨åˆ†æ‰¹å¤„ç†ï¼ˆå¾…å®ç°ï¼‰"
        )

    return suggestions


def analyze_symbol_distribution(parse_results: list) -> dict:
    """åˆ†æç¬¦å·åˆ†å¸ƒï¼Œæ‰¾å‡ºä¼˜åŒ–ç‚¹"""
    symbol_patterns = defaultdict(int)
    large_files = []

    for result in parse_results:
        symbol_count = len(result.symbols)
        if symbol_count > 50:
            large_files.append((result.path.name, symbol_count))

        # ç»Ÿè®¡ç¬¦å·åç§°æ¨¡å¼
        for symbol in result.symbols:
            name = symbol.name.lower()
            if name.startswith("get"):
                symbol_patterns["get*"] += 1
            elif name.startswith("set"):
                symbol_patterns["set*"] += 1
            elif name.startswith("is") or name.startswith("has"):
                symbol_patterns["is*/has*"] += 1
            elif symbol.kind == "class":
                symbol_patterns["classes"] += 1
            else:
                symbol_patterns["other"] += 1

    return {
        "patterns": dict(symbol_patterns),
        "large_files": sorted(large_files, key=lambda x: x[1], reverse=True)[:10],
    }


def main():
    """ä¸»å‡½æ•°"""
    console.print(Panel.fit(
        "[bold cyan]AI Enhancement å¤±è´¥è¯Šæ–­å·¥å…·[/bold cyan]\n"
        "[dim]åˆ†æpromptå¤§å°ã€ä¼°ç®—è¶…æ—¶ã€æä¾›ä¼˜åŒ–å»ºè®®[/dim]",
        border_style="cyan"
    ))

    # è¯»å–é…ç½®
    config = Config.load()
    timeout_config = 120  # ä»cliå‚æ•°è¯»å–ï¼Œè¿™é‡Œhardcode

    # è·å–é¡¹ç›®è·¯å¾„
    if len(sys.argv) > 1:
        project_root = Path(sys.argv[1])
    else:
        project_root = Path.cwd()

    console.print(f"\n[bold]é¡¹ç›®è·¯å¾„[/bold]: {project_root}")
    console.print(f"[bold]é…ç½®[/bold]:")
    console.print(f"  - max_concurrent: {config.ai_enhancement.max_concurrent}")
    console.print(f"  - rate_limit_delay: {config.ai_enhancement.rate_limit_delay}s")
    console.print(f"  - size_threshold: {config.ai_enhancement.size_threshold / 1024:.0f}KB")
    console.print(f"  - timeout: {timeout_config}s")

    # æŸ¥æ‰¾æ‰€æœ‰å¯ç´¢å¼•ç›®å½•
    from codeindex.scanner import find_all_directories

    dirs = find_all_directories(project_root, config)
    console.print(f"\n[bold]æ‰¾åˆ° {len(dirs)} ä¸ªç›®å½•[/bold]\n")

    # åˆ†ææ¯ä¸ªç›®å½•
    analyses = {}
    for i, dir_path in enumerate(dirs, 1):
        console.print(f"[dim]({i}/{len(dirs)})[/dim] ", end="")
        analysis = analyze_directory_prompt_size(dir_path, config)
        analyses[dir_path] = analysis

    # ç”ŸæˆæŠ¥å‘Š
    console.print("\n" + "=" * 80)
    console.print("[bold cyan]è¯Šæ–­æŠ¥å‘Š[/bold cyan]")
    console.print("=" * 80 + "\n")

    # 1. æ€»ä½“ç»Ÿè®¡
    console.print("[bold]1. æ€»ä½“ç»Ÿè®¡[/bold]\n")

    table = Table(title="Promptå¤§å°åˆ†å¸ƒ")
    table.add_column("çŠ¶æ€", style="cyan")
    table.add_column("æ•°é‡", justify="right")
    table.add_column("ç™¾åˆ†æ¯”", justify="right")

    status_counts = defaultdict(int)
    for analysis in analyses.values():
        status_counts[analysis["status"]] += 1

    status_styles = {
        "ok": "green",
        "large": "yellow",
        "risky": "orange",
        "too_large": "red",
        "empty": "dim",
    }

    total = len(analyses)
    for status in ["ok", "large", "risky", "too_large", "empty"]:
        count = status_counts[status]
        pct = count / total * 100 if total > 0 else 0
        table.add_row(
            f"[{status_styles[status]}]{status}[/{status_styles[status]}]",
            str(count),
            f"{pct:.1f}%",
        )

    console.print(table)

    # 2. é—®é¢˜ç›®å½•è¯¦æƒ…
    console.print("\n[bold]2. éœ€è¦å…³æ³¨çš„ç›®å½•[/bold]\n")

    problem_dirs = [
        (path, analysis)
        for path, analysis in analyses.items()
        if analysis["status"] in ["risky", "too_large"]
    ]

    if problem_dirs:
        detail_table = Table()
        detail_table.add_column("ç›®å½•")
        detail_table.add_column("æ–‡ä»¶æ•°", justify="right")
        detail_table.add_column("ç¬¦å·æ•°", justify="right")
        detail_table.add_column("Promptå¤§å°", justify="right")
        detail_table.add_column("çŠ¶æ€")
        detail_table.add_column("å»ºè®®è¶…æ—¶", justify="right")

        for dir_path, analysis in sorted(
            problem_dirs, key=lambda x: x[1]["prompt_size"], reverse=True
        ):
            prompt_kb = analysis["prompt_size"] / 1024
            estimated_timeout = estimate_timeout_needed(analysis)

            status_style = status_styles[analysis["status"]]
            detail_table.add_row(
                dir_path.name,
                str(analysis["files"]),
                str(analysis["symbols"]),
                f"{prompt_kb:.1f}KB",
                f"[{status_style}]{analysis['status']}[/{status_style}]",
                f"{estimated_timeout}s",
            )

        console.print(detail_table)

        # 3. æ¯ä¸ªé—®é¢˜ç›®å½•çš„è¯¦ç»†å»ºè®®
        console.print("\n[bold]3. æ”¹è¿›å»ºè®®[/bold]\n")

        for dir_path, analysis in problem_dirs[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            console.print(f"\n[bold cyan]ğŸ“ {dir_path.name}[/bold cyan]")

            suggestions = suggest_improvements(analysis, timeout_config)
            for suggestion in suggestions:
                console.print(f"  {suggestion}")

            # ç¬¦å·åˆ†å¸ƒåˆ†æ
            if "parse_results" in analysis:
                dist = analyze_symbol_distribution(analysis["parse_results"])
                if dist["patterns"]:
                    console.print(f"\n  [dim]ç¬¦å·åˆ†å¸ƒï¼š[/dim]")
                    for pattern, count in sorted(
                        dist["patterns"].items(), key=lambda x: x[1], reverse=True
                    ):
                        console.print(f"    - {pattern}: {count}ä¸ª")

                if dist["large_files"]:
                    console.print(f"\n  [dim]æœ€å¤§çš„æ–‡ä»¶ï¼ˆç¬¦å·æ•°ï¼‰ï¼š[/dim]")
                    for filename, count in dist["large_files"][:5]:
                        console.print(f"    - {filename}: {count}ä¸ªç¬¦å·")

    else:
        console.print("[green]âœ“ æ‰€æœ‰ç›®å½•çš„promptå¤§å°éƒ½åœ¨å®‰å…¨èŒƒå›´å†…[/green]")

    # 4. é…ç½®å»ºè®®
    console.print("\n[bold]4. é…ç½®ä¼˜åŒ–å»ºè®®[/bold]\n")

    # è®¡ç®—å¹³å‡promptå¤§å°
    avg_prompt_size = sum(a["prompt_size"] for a in analyses.values()) / len(analyses)
    max_prompt_size = max(a["prompt_size"] for a in analyses.values())

    console.print(f"å¹³å‡Promptå¤§å°: {avg_prompt_size / 1024:.1f}KB")
    console.print(f"æœ€å¤§Promptå¤§å°: {max_prompt_size / 1024:.1f}KB\n")

    config_suggestions = []

    # å¹¶å‘å»ºè®®
    risky_count = status_counts["risky"] + status_counts["too_large"]
    if risky_count > 0:
        config_suggestions.append(
            "ğŸ”§ max_concurrent: é™ä½åˆ° 2-4ï¼Œé¿å…åŒæ—¶å¤„ç†å¤šä¸ªå¤§ç›®å½•"
        )

    # è¶…æ—¶å»ºè®®
    max_estimated_timeout = max(
        estimate_timeout_needed(a) for a in analyses.values()
    )
    if max_estimated_timeout > timeout_config:
        config_suggestions.append(
            f"â±  timeout: å¢åŠ åˆ° {max_estimated_timeout}ç§’ï¼ˆå½“å‰{timeout_config}ç§’ï¼‰"
        )

    # rate limitå»ºè®®
    if config.ai_enhancement.max_concurrent > 4:
        config_suggestions.append(
            "ğŸš¦ rate_limit_delay: å¢åŠ åˆ° 2.0ç§’ï¼Œç»™APIæ›´å¤šå–˜æ¯æ—¶é—´"
        )

    if config_suggestions:
        console.print("[yellow]å»ºè®®è°ƒæ•´é…ç½®ï¼š[/yellow]\n")
        for suggestion in config_suggestions:
            console.print(f"  {suggestion}")
    else:
        console.print("[green]âœ“ å½“å‰é…ç½®è¾ƒä¸ºåˆç†[/green]")

    # 5. ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    console.print("\n[bold]5. ä¸‹ä¸€æ­¥è¡ŒåŠ¨[/bold]\n")

    actions = []

    if problem_dirs:
        actions.append("1. å¯¹äºrisky/too_largeçš„ç›®å½•ï¼Œæ‰‹åŠ¨è°ƒæ•´timeouté‡è¯•")
        actions.append("2. è€ƒè™‘å°†å¤§ç›®å½•æ‹†åˆ†ä¸ºæ›´å°çš„å­ç›®å½•")
        actions.append("3. å¯ç”¨exclude_patternsæ’é™¤get*/set*æ–¹æ³•")

    if risky_count > len(dirs) * 0.3:  # è¶…è¿‡30%çš„ç›®å½•æœ‰é—®é¢˜
        actions.append("4. ç­‰å¾…Epic 3.1å®æ–½ï¼ˆprompt compressionï¼‰")
        actions.append("5. æˆ–è€…ä½¿ç”¨--no-aiæš‚æ—¶ç¦ç”¨AIå¢å¼º")

    if not actions:
        actions.append("âœ“ å½“å‰é¡¹ç›®é€‚åˆAIå¢å¼ºï¼Œå¯ä»¥æ­£å¸¸è¿è¡Œscan-all")

    for action in actions:
        console.print(f"  {action}")

    console.print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
