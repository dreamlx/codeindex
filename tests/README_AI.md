<!-- Generated by codeindex at 2026-01-27T19:25:34+08:00 -->

# README_AI.md - tests

## Purpose
Test suite for the codeindex package, providing comprehensive unit tests for core components including directory tree building, code parsing, smart writing functionality, symbol importance scoring with visibility-based, semantic importance, documentation quality, complexity-based, and naming pattern (noise detection) ranking, adaptive symbols configuration, adaptive symbol selector with size-based limits, configuration loading with adaptive symbols support, SmartWriter integration with adaptive symbol selection, technical debt detection with both unit tests and BDD scenarios, symbol overload detection with massive symbol count and high noise ratio detection, super large file detection with multi-turn dialogue strategy recommendation, and shared test utilities.

## Architecture
The test suite is organized into twelve main test modules that mirror the core components of the codeindex package, plus a shared test utilities module and BDD feature files:
- `conftest.py` provides shared test fixtures and utilities including mock symbol creation, mock parse result creation supporting both normal file scenarios and God Class scenarios, and common fixtures for configuration and symbol scoring
- `test_directory_tree.py` validates directory structure traversal and tree building
- `test_parser.py` verifies code parsing capabilities for Python and PHP
- `test_smart_writer.py` tests intelligent README generation with different detail levels
- `test_smart_writer_adaptive.py` tests SmartWriter integration with adaptive symbol selection, including backward compatibility, size-based limits, real-world scenarios, multiple files, and file lines counting
- `test_symbol_scorer.py` validates symbol importance scoring with contextual awareness, visibility scoring, semantic importance scoring, documentation quality scoring, complexity scoring, and naming pattern scoring across languages
- `test_adaptive_config.py` validates adaptive symbols configuration data structures, default values, validation rules, and configuration overrides
- `test_adaptive_selector.py` validates AdaptiveSymbolSelector with size-based category determination, constraint application, and dynamic limit calculation
- `test_config_adaptive.py` validates Config class integration with adaptive symbols configuration, YAML loading, backward compatibility, and configuration merging
- `test_tech_debt_detector.py` validates technical debt detection including severity levels, debt issues, analysis results, file size detection using FileSizeClassifier (Epic 4 refactoring), God Class detection, and quality score calculation
- `test_tech_debt_bdd.py` provides BDD-style tests using pytest-bdd with Gherkin feature files for scenario-driven technical debt, symbol overload, and super large file detection validation
- `test_symbol_overload.py` validates symbol overload detection including SymbolOverloadAnalysis dataclass, massive symbol count detection (>100 symbols), high noise ratio detection (>50% low-quality symbols), noise breakdown categorization, and integration tests with real-world scenarios
- `test_super_large_detection_bdd.py` validates super large file detection using BDD scenarios with line count thresholds (>5000 lines), symbol count thresholds (>100 symbols), and enhancement strategy recommendations (multi_turn, hierarchical, standard)

## Key Components
- `create_mock_symbol()`: Factory function for creating mock Symbol objects with customizable attributes (name, kind, signature, docstring, line ranges)
- `create_mock_parse_result()`: Factory function for creating mock ParseResult objects supporting both normal file scenarios (with symbol_count) and God Class scenarios (with class_name and methods_per_class)
- `mock_config`: pytest fixture providing a Config instance
- `symbol_scorer`: pytest-bdd fixture providing a SymbolImportanceScorer
- `tech_debt_detector`: pytest-bdd fixture providing a TechDebtDetector with default configuration
- `_create_test_structure()`: Creates temporary directory structures for testing
- `_create_mock_symbols()`: Creates mock Symbol objects for adaptive testing
- `_create_mock_parse_result()`: Helper for creating mock parsing results with file_lines support
- `test_directory_tree_*`: Validates DirectoryTree class functionality including level determination, children management, and processing order
- `test_parse_*()`: Tests parsing of functions, classes, PHP syntax features, and error handling
- `test_smart_writer_*()`: Verifies README generation at different detail levels, file grouping, and size limits
- `TestSmartWriterAdaptiveDisabled`: Tests SmartWriter with adaptive disabled (backward compatibility with max_per_file)
- `TestSmartWriterAdaptiveEnabled`: Tests SmartWriter with adaptive enabled for small and large files, respecting total symbols constraint
- `TestRealWorldScenarios`: Validates SmartWriter behavior with real PHP project scenarios (8891 lines/57 symbols, 500 lines/80 symbols)
- `TestMultipleFiles`: Tests SmartWriter with mixed file sizes using individual adaptive limits
- `TestFileLinesCounting`: Validates file lines counting mechanism from ParseResult
- `TestSymbolScorerBase`: Tests symbol scorer initialization, scoring consistency, and score differentiation
- `TestVisibilityScoring`: Validates visibility-based scoring for PHP (public/protected/private) and Python (public/private/magic methods)
- `TestSemanticScoring`: Validates semantic importance scoring based on method name keywords (critical: 25.0, secondary: 15.0, generic: 5.0)
- `TestDocumentationScoring`: Validates documentation quality scoring based on docstring length (long >200 chars: 15.0, medium >50 chars: 10.0, short: 5.0, none: 0.0)
- `TestComplexityScoring`: Validates complexity scoring based on method line count (>100 lines: 20.0, 50-100 lines: 15.0, 20-50 lines: 10.0, <20 lines: 5.0)
- `TestNamingPatternScoring`: Validates naming pattern scoring (noise detection) with penalties for getter/setter methods (-10.0), is/has methods (-10.0), private methods (-15.0), and magic methods (-20.0)
- `TestAdaptiveSymbolsConfig`: Validates AdaptiveSymbolsConfig data class, default configuration, custom initialization, and partial overrides
- `TestConfigurationValidation`: Validates configuration constraints (positive values, reasonable ranges, min/max bounds)
- `TestExpectedDefaults`: Validates default values match planning specifications
- `TestAdaptiveSymbolSelectorBase`: Tests selector initialization with default and custom configs, limit calculation returns positive integers, and respects total symbol count
- `TestSizeCategoryDetermination`: Validates file size categorization (tiny <100, small 100-200, medium 200-500, large 500-1000, xlarge 1000-2000, huge 2000-5000, mega â‰¥5000)
- `TestConstraintApplication`: Validates constraint enforcement (min_symbols, max_symbols, total_symbols)
- `TestEdgeCases`: Tests edge cases (zero lines, one line, extremely large files, total symbols less than limit)
- `TestCustomConfiguration`: Tests selector with custom thresholds and limits
- `TestConsistency`: Validates deterministic behavior and consistency across selector instances
- `TestSymbolsConfigAdaptive`: Validates SymbolsConfig integration with adaptive_symbols field and default behavior
- `TestConfigLoadingAdaptive`: Validates Config.load() with adaptive symbols configuration from YAML files
- `TestConfigurationMerging`: Validates user configuration merging with default values for thresholds and limits
- `TestBackwardCompatibility`: Validates backward compatibility with existing configurations without adaptive symbols
- `TestDebtSeverity`: Validates DebtSeverity enum levels and ordering (CRITICAL < HIGH < MEDIUM < LOW)
- `TestDebtIssue`: Validates DebtIssue dataclass with severity, category, file path, metric value, threshold, description, and suggestion
- `TestDebtAnalysisResult`: Validates DebtAnalysisResult dataclass with issues list, quality score, file path, file lines, and total symbols
- `TestTechDebtDetector`: Validates TechDebtDetector initialization with FileSizeClassifier integration (Epic 4 refactoring) for file size detection (classifier.super_large_lines=5000, classifier.super_large_symbols=100) and GOD_CLASS_METHODS=50
- `TestFileSizeDetection`: Validates file size detection with super large files (>5000 lines, CRITICAL severity), large files (>2000 lines, HIGH severity), boundary conditions, and split suggestions
- `TestGodClassDetection`: Validates God Class detection (>50 methods, CRITICAL severity), split suggestions with method count calculation, boundary conditions, multiple God Classes in one file, Python-style method names (ClassName.method_name), PHP-style method names (ClassName::method_name), and differentiation from standalone functions
- `TestQualityScoreCalculation`: Validates quality score calculation (100 base - severity penalties), CRITICAL penalty (-30), HIGH penalty (-15), cumulative penalties for multiple issues, minimum score of 0, mixed severities, and score decrease correlation with issue count
- `TestSymbolOverloadAnalysis`: Validates SymbolOverloadAnalysis dataclass with total_symbols, filtered_symbols, filter_ratio, noise_breakdown, and quality_score fields
- `TestSymbolCountDetection`: Validates massive symbol count detection (>100 symbols triggers CRITICAL), boundary conditions (100 symbols no issue, 101 symbols flagged), and normal symbol counts
- `TestNoiseRatioDetection`: Validates high noise ratio detection (>50% low-quality symbols triggers HIGH severity) with mixed quality symbols
- `TestNoiseBreakdown`: Validates noise categorization into getters/setters, private methods, and magic methods
- `TestIntegration`: Integration tests for symbol overload detection with real-world scenarios (57 symbols in 8891 line file)
- BDD step definitions: `@given`, `@when`, `@then` steps for scenario-driven technical debt, symbol overload, and super large file detection testing with parameterized fixtures for file data, language types, symbol counts, class structures, symbol overload analysis results, detection results, strategy results, custom threshold configuration, and project file collections

## Consumes
| Module | Purpose |
|--------|---------|
| codeindex.adaptive_config | AdaptiveSymbolsConfig, DEFAULT_ADAPTIVE_CONFIG for adaptive behavior configuration |
| codeindex.adaptive_selector | AdaptiveSymbolSelector for size-based symbol limit calculation |
| codeindex.ai_enhancement | is_super_large_file, select_enhancement_strategy for super large file detection and strategy selection |
| codeindex.config | Config, GroupingConfig, IndexingConfig, SymbolsConfig for configuration management |
| codeindex.directory_tree | DirectoryTree class for structure validation |
| codeindex.file_classifier | FileSizeClassifier for unified file size classification (used by TechDebtDetector after Epic 4 refactoring) |
| codeindex.parser | Import, ParseResult, Symbol classes and parse_file function |
| codeindex.smart_writer | SmartWriter class and determine_level function |
| codeindex.symbol_scorer | SymbolImportanceScorer, ScoringContext for importance ranking |
| codeindex.tech_debt | TechDebtDetector, DebtAnalysisResult, DebtIssue, DebtSeverity, SymbolOverloadAnalysis for technical debt and symbol overload detection |
| pytest | Test fixtures and utilities |
| pytest_bdd | BDD-style testing with scenarios, given, when, then decorators and parsers |
| tempfile | Temporary file and directory creation for testing |
| pathlib | Path handling for configuration files |
| yaml | YAML file serialization for configuration testing |

## Provides
| Export | Purpose |
|--------|---------|
| create_mock_symbol | Factory function for creating mock Symbol instances with customizable parameters (name, kind, signature, docstring, line ranges) |
| create_mock_parse_result | Factory function for creating mock ParseResult instances supporting normal files (with symbol_count) and God Class scenarios (with class_name and methods_per_class for large files with many methods) |
| mock_config | pytest fixture providing a Config instance for testing |
| symbol_scorer | pytest fixture providing a SymbolImportanceScorer instance for testing |
| Test cases | Validates core package functionality |
| Test utilities | Helper functions for creating test data and structures |
| Visibility scoring tests | Validates language-specific visibility scoring rules |
| Semantic scoring tests | Validates keyword-based semantic importance scoring with case-insensitive matching |
| Documentation scoring tests | Validates docstring-based quality scoring (long/medium/short/none) |
| Complexity scoring tests | Validates line-count-based complexity scoring (very large/large/medium/small methods) |
| Naming pattern scoring tests | Validates noise detection penalties for getter/setter methods, boolean check methods, private methods, and magic methods |
| Adaptive config tests | Validates adaptive symbols configuration data structure, defaults, thresholds, limits, and validation rules |
| Adaptive selector tests | Validates AdaptiveSymbolSelector with size category determination, limit calculation, constraint application, edge cases, real-world scenarios, custom configurations, and consistency |
| SmartWriter adaptive tests | Validates SmartWriter integration with adaptive symbol selection, backward compatibility, and file-specific limits |
| Config loading tests | Validates YAML configuration loading with adaptive symbols support |
| Backward compatibility tests | Validates existing configurations continue to work without adaptive symbols |
| Configuration merging tests | Validates user overrides merge correctly with defaults |
| Technical debt detection tests | Validates technical debt detection including DebtSeverity enum, DebtIssue and DebtAnalysisResult dataclasses, TechDebtDetector initialization with FileSizeClassifier (Epic 4), file size detection (super large and large files), God Class detection (PHP and Python), and quality score calculation with severity-based penalties |
| Symbol overload detection tests | Validates SymbolOverloadAnalysis dataclass, massive symbol count detection (>100 symbols CRITICAL), high noise ratio detection (>50% low-quality symbols HIGH), noise breakdown categorization (getters/setters, private methods, magic methods), and real-world integration scenarios |
| Super large file detection tests | Validates super large file detection using BDD scenarios with is_super_large_file function, line count thresholds (>5000 lines), symbol count thresholds (>100 symbols), detection reasons, strategy recommendations (multi_turn for complexity, hierarchical for structure, standard for normal), custom threshold configuration, multi-file strategy selection, and logging verification |
| BDD scenario tests | Validates technical debt detection, symbol overload detection, and super large file detection through Gherkin scenarios with given-when-then steps, parameterized test data, behavior-driven validation, and flexible fixture resolution using pytest request object |

## Test Coverage
- Directory tree building and traversal logic
- Code parsing for Python and PHP languages
- Multi-level README generation
- File grouping and symbol filtering
- SmartWriter with adaptive disabled (uses max_per_file for backward compatibility)
- SmartWriter with adaptive enabled for small files (uses small category limit)
- SmartWriter with adaptive enabled for large files (uses large/huge/mega category limits)
- SmartWriter respects total_symbols constraint (doesn't exceed actual symbol count)
- SmartWriter real-world scenarios (8891 lines/57 symbols PHP file, 500 lines/80 symbols file)
- SmartWriter with multiple files of mixed sizes (each file uses its own adaptive limit)
- SmartWriter file_lines counting from ParseResult for category determination
- Symbol importance scoring with context awareness
- Visibility-based scoring (PHP: public=20, protected=10, private=0; Python: public=15, private/magic=5)
- Semantic importance scoring (critical keywords=25.0, secondary keywords=15.0, generic=5.0)
- Documentation quality scoring (long docstrings=15.0, medium=10.0, short=5.0, none/null=0.0)
- Complexity scoring (>100 lines=20.0, 50-100 lines=15.0, 20-50 lines=10.0, <20 lines=5.0)
- Naming pattern scoring (getter/setter=-10.0, is/has methods=-10.0, private methods=-15.0, magic methods=-20.0, normal methods=0.0)
- Adaptive configuration data class instantiation and defaults
- Configuration thresholds (tiny=100, small=200, medium=500, large=1000, xlarge=2000, huge=5000)
- Configuration limits (tiny=10, small=15, medium=30, large=50, xlarge=80, huge=120, mega=150)
- Configuration validation (positive values, increasing thresholds/limits, min=5/max=200 symbols)
- Configuration overrides and partial customization
- AdaptiveSymbolSelector initialization with default and custom configs
- Size category determination for all size ranges (tiny through mega)
- Size category boundary conditions (99, 100, 199, 200, etc.)
- Limit calculation returns positive integers not exceeding total symbols
- Constraint application (min_symbols, max_symbols, total_symbols)
- Edge cases (zero lines, one line, extremely large files, insufficient symbols)
- Real-world PHP file sizes (8891, 7924, 3521, 500 lines)
- Custom threshold and limit configurations
- Selector consistency and determinism across instances
- SymbolsConfig integration with adaptive_symbols field
- Config.load() with adaptive symbols from YAML files
- YAML loading without adaptive symbols (backward compatibility)
- YAML loading with enabled adaptive symbols
- YAML loading with custom thresholds and limits
- YAML loading with partial threshold/limit overrides
- YAML loading with min_symbols and max_symbols
- Configuration merging preserves user-specified values
- Empty adaptive_symbols configuration uses defaults
- Old configuration files without adaptive symbols continue working
- Backward compatibility (disabled by default)
- Case-insensitive keyword matching for semantic scoring
- Scorer initialization and consistency
- Score range validation (0-100)
- Error handling and edge cases
- Size limit enforcement
- Mock symbol creation with customizable attributes
- Mock parse result creation for normal and God Class scenarios
- Shared test fixtures for configuration and symbol scoring
- DebtSeverity enum with four levels (CRITICAL, HIGH, MEDIUM, LOW) and ordering
- DebtIssue dataclass with all required fields (severity, category, file_path, metric_value, threshold, description, suggestion)
- DebtAnalysisResult dataclass with issues list, quality score, file path, file lines, and total symbols
- TechDebtDetector initialization with FileSizeClassifier integration (Epic 4 refactoring)
- TechDebtDetector uses classifier for file size detection (classifier.super_large_lines=5000, classifier.super_large_symbols=100)
- TechDebtDetector GOD_CLASS_METHODS threshold (50 methods)
- Super large file detection (>5000 lines, CRITICAL severity with split suggestion)
- Large file detection (>2000 lines, HIGH severity, not CRITICAL)
- Normal file with no size issues
- File size boundary conditions (2000, 2001, 5000, 5001 lines)
- Super large file takes precedence over large file detection
- God Class detection (>50 methods, CRITICAL severity)
- God Class split suggestion with method count calculation
- God Class boundary conditions (50, 51 methods)
- Multiple God Classes in one file detection
- Python-style method names (ClassName.method_name)
- PHP-style method names (ClassName::method_name)
- Standalone functions excluded from God Class detection
- Quality score calculation (100 base score)
- Quality score with CRITICAL issue (-30 penalty)
- Quality score with HIGH issue (-15 penalty)
- Quality score with multiple issues (cumulative penalties)
- Quality score minimum of 0 (cannot go below zero)
- Quality score with mixed severities
- Quality score decreases with more issues
- SymbolOverloadAnalysis dataclass creation with all fields (total_symbols, filtered_symbols, filter_ratio, noise_breakdown, quality_score)
- SymbolOverloadAnalysis with no noise (empty breakdown, 0.0 filter_ratio, 100.0 quality_score)
- Massive symbol count detection (>100 symbols triggers CRITICAL severity)
- Normal symbol count (no massive_symbol_count issue)
- Symbol count boundary conditions (100 symbols no issue, 101 symbols CRITICAL)
- High noise ratio detection (>50% low-quality symbols triggers HIGH severity with low_quality_symbols category)
- Low noise ratio (no low_quality_symbols issue)
- Mixed quality symbols (20 getters, 10 business methods)
- Noise breakdown categorization (getters_setters, private_methods, magic_methods)
- Integration test with real-world scenario (57 symbols, 8891 lines PHP file)
- Super large file detection by line count (>5000 lines)
- Super large file detection by symbol count (>100 symbols)
- Super large file detection with both line and symbol thresholds exceeded
- Normal file not detected as super large (2000 lines, 50 symbols)
- Detection reason validation (line_count, symbol_count)
- Multi-turn dialogue strategy recommendation for complex files
- Standard AI enhancement strategy recommendation for normal files
- Hierarchical prompt strategy recommendation for structured files
- Custom threshold configuration (super_large_file_lines, super_large_file_symbols)
- Multi-file strategy selection with mixed sizes
- Strategy selection logging
- Detection respects custom thresholds
- BDD scenarios for well-structured code (no CRITICAL/HIGH issues, quality >80)
- BDD scenarios for super large files (>5000 lines, CRITICAL file_size issue, split recommendation)
- BDD scenarios for large files (>2000 lines, HIGH file_size issue)
- BDD scenarios for God Classes (>50 methods, CRITICAL god_class issue, extract classes recommendation)
- BDD scenarios for combined debt (super large files with God Classes, multiple issues, quality <50)
- BDD scenarios for symbol overload detection (PHP files with 50/150 symbols, massive symbol count detection, CRITICAL severity validation)
- BDD scenarios for super large file detection (Python/PHP files with various line counts and symbol counts, strategy recommendations)
- BDD parameterized steps for file creation with line counts, symbol counts, and languages (Python/PHP)
- BDD parameterized steps for symbol and class creation
- BDD parameterized steps for symbol overload analysis with fixture resolution using pytest request object
- BDD parameterized steps for detection result validation and strategy result validation
- BDD parameterized steps for custom threshold configuration using data tables
- BDD parameterized steps for project file collections with expected strategies
- BDD assertion steps for issue severity, categories, descriptions, suggestions, and quality scores
- BDD assertion steps for super large file detection (is_super_large, detection reason, recommended strategy)
- BDD assertion steps using flexible fixture resolution to handle both analysis_result, symbol_overload_result, detection_result, and strategy_results fixtures

**Commit `bdd6e65`**: test(tech-debt): add 22 TDD tests for reporting

Changed files:
- `test_tech_debt_formatters.py`
- `test_tech_debt_reporter.py`

**Commit `e113714`**: test(tech-debt): add 5 BDD scenarios for reporting

Changed files:
- `test_tech_debt_bdd.py`


**Commit `9dd8178`**: test(cli): add 12 integration tests for tech-debt command

Changed files:
- `test_cli_tech_debt.py`

**Commit `73a3c57`**: feat(epic3.2): implement super large file detection (Story 3.2.1)

Changed files:
- `test_super_large_detection_bdd.py`


**Commit `51094c0`**: feat(epic3.2): implement multi-turn dialogue core (Story 3.2.2 WIP)

Changed files:
- `test_multi_turn_dialogue_bdd.py`


**Commit `b50dfeb`**: test(epic3.2): complete BDD tests for multi-turn dialogue (Story 3.2.2)

Changed files:
- `test_multi_turn_dialogue_bdd.py`


**Commit `07b7535`**: feat(epic4): implement AI helper module with aggregate and multi-turn functions (Story 4.1 Tasks 4.1.1-4.1.3)

Changed files:
- `test_ai_helper.py`


**Commit `1d7fff0`**: feat(epic4): implement unified file size classifier (Story 4.2 Tasks 4.2.1-4.2.2)

Changed files:
- `test_file_classifier.py`

**Commit `da32693`**: refactor(epic4): integrate FileSizeClassifier into tech_debt and ai_enhancement (Story 4.2 Tasks 4.2.3-4.2.4)

Changed files:
- `test_tech_debt_detector.py` - Updated tests to verify TechDebtDetector uses FileSizeClassifier instead of hard-coded constants for file size detection

---

## Recent Changes

**Commit `dbf84a2`**: feat(semantic): implement SemanticExtractor foundation (Story 4.4, Task 4.4.1 Day 1)

Changed files:
- `test_semantic_extractor.py`
