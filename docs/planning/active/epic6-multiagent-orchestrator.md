# Epic 6: Multi-agent Orchestrator Infrastructure

**Created**: 2026-02-01
**Epic Type**: Platform Infrastructure
**Target Version**: v0.5.0
**Status**: ğŸ“‹ Planning â†’ ğŸ§ª MVP Validation
**Strategic Importance**: â­â­â­â­â­ (Critical differentiator)

---

## ğŸ¯ Epic Vision

**From**: Single-agent sequential code analysis
**To**: Multi-agent concurrent AI compute platform

Transform codeindex into an **AIç®—åŠ›è°ƒåº¦å¹³å°**ï¼Œåˆ©ç”¨ headless Claude/Opencode çš„å¹¶å‘èƒ½åŠ›ï¼Œå°†ä»£ç åˆ†æé€Ÿåº¦æå‡ 10-100 å€ï¼Œä¸ºä¸Šå¸‚å…¬å¸æä¾›"ç”¨ç®—åŠ›æ¢é€Ÿåº¦"çš„å·®å¼‚åŒ–ä»·å€¼ã€‚

---

## ğŸ“Š Business Context

### Problem Statement

**å½“å‰ç—›ç‚¹**ï¼š
- å• agent ä¸²è¡Œå¤„ç†å¤§è§„æ¨¡ä»£ç åº“è€—æ—¶æ•°å°æ—¶
- ç«äº‰å¯¹æ‰‹ï¼ˆSonarQubeã€CodeClimateï¼‰åªæœ‰é™æ€åˆ†æï¼Œæ— è¯­ä¹‰ç†è§£
- ç°æœ‰ AI å·¥å…·ï¼ˆGitHub Copilotï¼‰éƒ½æ˜¯å• agentï¼Œæ…¢

**ç›®æ ‡å®¢æˆ·**ï¼š
- ä¸Šå¸‚å…¬å¸ã€ä¸­å¤§å‹è½¯ä»¶å…¬å¸
- æœ‰å¤šå®¢æˆ·å®šåˆ¶ç‰ˆæœ¬çš„ SaaS å…¬å¸
- éœ€è¦å¿«é€Ÿä»£ç å®¡æŸ¥å’Œé‡å¤æ£€æµ‹çš„å›¢é˜Ÿ

**å®¢æˆ·è¯‰æ±‚**ï¼š
- â±ï¸ **é€Ÿåº¦** - "æˆ‘æ„¿æ„ä»˜é’±ï¼Œä½†ä¸æ„¿æ„ç­‰"
- ğŸ¯ **å‡†ç¡®** - "AST åˆ†æå¤ªç²—ç³™ï¼Œæˆ‘è¦è¯­ä¹‰ç†è§£"
- ğŸ“ˆ **è§„æ¨¡** - "æˆ‘æœ‰100+åˆ†æ”¯ï¼Œéœ€è¦æ‰¹é‡åˆ†æ"

### Value Proposition

**Slogan**: "AI ç®—åŠ›é›†ç¾¤ï¼Œ10åˆ†é’Ÿé¡¶10å°æ—¶"

| ç»´åº¦ | ä¼ ç»Ÿå·¥å…· | å• AI agent | codeindex v0.5.0 (Multi-agent) |
|------|---------|-------------|-------------------------------|
| **é€Ÿåº¦** | 5åˆ†é’Ÿ | 2å°æ—¶ | **10åˆ†é’Ÿ** âš¡ |
| **è´¨é‡** | 60%å‡†ç¡®ç‡ | 85%å‡†ç¡®ç‡ | **95%å‡†ç¡®ç‡** ğŸ¯ |
| **è§„æ¨¡** | å•é¡¹ç›® | å•é¡¹ç›® | **100+åˆ†æ”¯å¹¶å‘** ğŸ“ˆ |
| **æˆæœ¬** | å…è´¹ | $50 | $500 (ä½†èŠ‚çœ8å°æ—¶äººå·¥) |

**ROI è®¡ç®—**ï¼š
- èŠ‚çœæ—¶é—´ï¼š110åˆ†é’Ÿ
- å¼€å‘è€…æ—¶è–ªï¼š$100/hour
- æ—¶é—´ä»·å€¼ï¼š$183
- AI æˆæœ¬ï¼š$450
- **å‡€æ”¶ç›Š**ï¼šæ—¶é—´èŠ‚çœ > æˆæœ¬ï¼ˆä¸”ä½“éªŒå¤§å¹…æå‡ï¼‰

---

## ğŸ—ï¸ Architecture Overview

### Current Architecture (v0.3.2)

```
codeindex (Python)
    â†“ ai_command
Claude CLI (single agent)
    â†“ sequential
Analyze code one by one
    â†“
README_AI.md
```

**æ€§èƒ½**ï¼š1000ä¸ªå‡½æ•° = 500ç§’

### New Architecture (v0.5.0)

```
codeindex (Python)
    â†“ ai_command with orchestrator
Claude CLI â†’ Orchestrator Skill
    â†“ (internal parallel Task calls)
    â”œâ”€â†’ Worker 1 (Claude/Opencode) â”€â”€â”
    â”œâ”€â†’ Worker 2 (Claude/Opencode) â”€â”€â”¤
    â”œâ”€â†’ Worker 3 (Claude/Opencode) â”€â”€â”¼â”€â†’ Result Aggregator
    â”œâ”€â†’ ...                         â”€â”€â”¤
    â””â”€â†’ Worker N (Claude/Opencode) â”€â”€â”˜
    â†“
Final Report
```

**æ€§èƒ½**ï¼š1000ä¸ªå‡½æ•° with 50 workers = 15ç§’

### Key Components

**1. Orchestrator Skill** (Claude agent)
- Task decomposition (åˆ†è§£ä»»åŠ¡)
- Worker scheduling (è°ƒåº¦)
- Result aggregation (èšåˆ)

**2. Worker Skill** (Claude/Opencode agent)
- Code analysis execution
- Semantic similarity detection
- Structured result output

**3. Python Invoker** (Enhanced)
- Mode detection (simple vs orchestrator)
- File I/O for large data
- Configuration management

**4. Configuration** (.codeindex.yaml)
- Orchestrator mode toggle
- Max workers setting
- Backend selection (Claude/Opencode/mixed)

---

## ğŸ“‹ Stories and Tasks

### Story 6.1: Orchestrator Skill Foundation

**As a** codeindex user
**I want** multi-agent orchestration capability
**So that** my code analysis can run 10x faster

#### Acceptance Criteria

**AC1**: Orchestrator can decompose task into batches
```python
# Input: 100 functions
orchestrator.decompose(functions, num_workers=10)
# Output: 10 batches of 10 functions each
```

**AC2**: Orchestrator can launch workers in parallel
```python
# Launch 10 workers concurrently via Task tool
# All workers complete within 2x single-worker time
```

**AC3**: Orchestrator aggregates results correctly
```python
# 10 workers return results
# Orchestrator merges into single report
# No duplicates, no missing results
```

#### Tasks

- [ ] **Task 6.1.1**: Create orchestrator skill template (2 days)
  - skill.md definition
  - Task decomposition logic
  - Batch file writing

- [ ] **Task 6.1.2**: Implement parallel worker launching (3 days)
  - Single message with multiple Task calls
  - Handle 2, 5, 10 workers
  - Verify parallelism

- [ ] **Task 6.1.3**: Implement result aggregation (2 days)
  - Read all worker outputs
  - Merge results
  - Conflict resolution (if needed)

- [ ] **Task 6.1.4**: Error handling (2 days)
  - Worker timeout handling
  - Worker failure retry
  - Partial failure tolerance

**Estimate**: 9 days

---

### Story 6.2: Worker Skill Implementation

**As an** orchestrator
**I want** specialized worker agents
**So that** I can distribute analysis tasks

#### Acceptance Criteria

**AC1**: Worker can analyze a batch of function pairs
```python
# Input: batch of 20 function pairs
# Output: similarity scores for each pair
# Time: < 30 seconds
```

**AC2**: Worker output is structured and parseable
```json
{
  "batch_id": 1,
  "results": [
    {"pair_id": 1, "similarity": 0.85, "is_duplicate": true}
  ]
}
```

**AC3**: Worker handles errors gracefully
```python
# If LLM call fails, return error without crashing
# If function unparseable, skip and log
```

#### Tasks

- [ ] **Task 6.2.1**: Create worker skill template (2 days)
  - skill.md definition
  - Batch reading logic
  - Output writing logic

- [ ] **Task 6.2.2**: Implement similarity analysis (3 days)
  - LLM prompt for semantic comparison
  - Scoring algorithm
  - Threshold filtering

- [ ] **Task 6.2.3**: Result formatting (1 day)
  - JSON output structure
  - Error reporting

- [ ] **Task 6.2.4**: Performance optimization (2 days)
  - Reduce token usage
  - Optimize prompt
  - Benchmark

**Estimate**: 8 days

---

### Story 6.3: Python Integration

**As a** developer
**I want** codeindex to support orchestrator mode
**So that** I can use multi-agent analysis from CLI

#### Acceptance Criteria

**AC1**: Configuration supports orchestrator mode
```yaml
ai:
  mode: "orchestrator"  # New config option
  orchestrator:
    max_workers: 10
```

**AC2**: Invoker detects mode and routes correctly
```python
invoker = AIInvoker(config)
# If mode="orchestrator", call orchestrator skill
# If mode="simple", use old behavior
```

**AC3**: CLI command works end-to-end
```bash
codeindex find-duplicates --commit HEAD --workers 10
# Successfully runs with 10 workers
# Outputs aggregated results
```

#### Tasks

- [ ] **Task 6.3.1**: Extend config schema (1 day)
  - Add ai.mode field
  - Add orchestrator section
  - Backward compatibility

- [ ] **Task 6.3.2**: Modify AIInvoker (3 days)
  - Mode detection
  - Task file creation
  - Orchestrator invocation
  - Result file reading

- [ ] **Task 6.3.3**: CLI command integration (2 days)
  - Add --workers flag
  - Progress display
  - Error handling

- [ ] **Task 6.3.4**: End-to-end testing (2 days)
  - Test with 1, 5, 10 workers
  - Verify results match single-agent
  - Performance benchmarking

**Estimate**: 8 days

---

### Story 6.4: MVP Validation

**As a** product owner
**I want** to validate multi-agent provides value
**So that** we can decide on full investment

#### Acceptance Criteria

**AC1**: Speed improvement â‰¥ 5x
```
Baseline (1 worker): 100 seconds
Test (10 workers): â‰¤ 20 seconds
Speedup: 5x âœ…
```

**AC2**: Quality maintained or improved
```
Baseline accuracy: 85%
Test accuracy: â‰¥ 85%
```

**AC3**: Cost increase < 15x
```
Baseline cost: $10
Test cost: â‰¤ $150 (overhead < 50%)
```

#### Tasks

- [ ] **Task 6.4.1**: Benchmark suite creation (2 days)
  - Create test dataset (100-500 functions)
  - Baseline measurement script
  - Metrics collection

- [ ] **Task 6.4.2**: Run experiments (3 days)
  - Test: 1, 5, 10, 20 workers
  - Measure: time, quality, cost
  - Document results

- [ ] **Task 6.4.3**: Analysis and decision (2 days)
  - ROI analysis
  - Bottleneck identification
  - Go/No-Go recommendation

**Estimate**: 7 days

---

## ğŸ“… Timeline

### Phase 1: MVP (4 weeks)

**Week 1: Orchestrator Foundation**
- Story 6.1 (Orchestrator Skill)
- Deliverable: Working orchestrator with 2-5 workers

**Week 2: Worker Implementation**
- Story 6.2 (Worker Skill)
- Deliverable: Worker that analyzes batches

**Week 3: Python Integration**
- Story 6.3 (Python Integration)
- Deliverable: End-to-end working CLI

**Week 4: Validation**
- Story 6.4 (MVP Validation)
- Deliverable: Performance data + Go/No-Go decision

### Phase 2: Production (4 weeks) - If MVP successful

**Week 5-6: Optimization**
- Story 6.5: Smart task partitioning
- Story 6.6: Caching mechanism
- Story 6.7: Mixed backend support (Claude + Opencode)

**Week 7-8: Robustness**
- Story 6.8: Advanced error handling
- Story 6.9: Performance tuning
- Story 6.10: Documentation and release

---

## ğŸ”§ Configuration Design

### .codeindex.yaml Extensions

```yaml
# Traditional mode (backward compatible)
ai_command: 'claude -p "{prompt}" --allowedTools "Read"'

# Or: Orchestrator mode
ai:
  mode: "orchestrator"  # "simple" | "orchestrator"
  command: "claude"

  orchestrator:
    skill: "codeindex-orchestrator"
    max_workers: 10           # Maximum concurrent workers
    strategy: "dynamic"       # "fixed" | "dynamic"
    timeout: 300              # Worker timeout (seconds)

  worker:
    skill: "code-analyzer-worker"
    retry: 3                  # Retry failed workers

  # Data transfer (large datasets)
  data:
    method: "file"            # "file" | "prompt"
    temp_dir: "/tmp/codeindex"
```

### Advanced Configuration (Phase 2)

```yaml
ai:
  mode: "orchestrator"

  # Mixed backend support
  backend: "mixed"  # "claude" | "opencode" | "mixed"

  mixed:
    backends:
      - name: "claude"
        command: "claude"
        weight: 0.7         # 70% tasks to Claude
      - name: "opencode"
        command: "opencode"
        weight: 0.3         # 30% tasks to Opencode
    strategy: "weighted"    # "round-robin" | "weighted" | "least-loaded"

  orchestrator:
    max_workers: 50

    # Smart partitioning
    partitioning:
      strategy: "complexity-based"  # "equal" | "complexity-based"
      min_batch_size: 5
      max_batch_size: 50

  # Caching
  cache:
    enabled: true
    backend: "sqlite"
    ttl: 86400
    path: ".codeindex/cache.db"
```

---

## ğŸ¯ Success Metrics

### Technical Metrics

| Metric | Baseline (v0.3.2) | Target (v0.5.0 MVP) | Target (v0.5.0 Final) |
|--------|-------------------|---------------------|----------------------|
| **Speed** | 500s (1000 funcs) | 50s (10 workers) | 15s (50 workers) |
| **Speedup** | 1x | 10x | 33x |
| **Quality** | 85% (single LLM) | â‰¥85% | â‰¥90% |
| **Max Scale** | 1000 functions | 5000 functions | 50000 functions |
| **Concurrency** | 1 agent | 10 agents | 100 agents |

### Business Metrics

| Metric | Target |
|--------|--------|
| **Customer Tier** | Enterprise (ä¸Šå¸‚å…¬å¸) |
| **Price Point** | $999-$4999/month |
| **Value Prop** | "10x faster than single-agent" |
| **Differentiation** | Only tool with 100-agent concurrency |

---

## ğŸš§ Risks and Mitigation

### Risk 1: Claude API Rate Limits

**Risk**: API provider limits concurrent requests
**Impact**: Can't achieve 100-agent concurrency
**Mitigation**:
- Start with 10-20 agents (safe)
- Support mixed backends (distribute load)
- Implement queuing if hit limits

### Risk 2: Worker Startup Overhead

**Risk**: Starting 100 agents takes too long
**Impact**: No net speedup
**Mitigation**:
- Measure overhead in MVP
- Implement worker pooling if needed
- Use dynamic worker count

### Risk 3: Result Inconsistency

**Risk**: Different agents give different similarity scores
**Impact**: Unreliable results
**Mitigation**:
- Use confidence thresholds
- Implement voting mechanism
- A/B test consistency

### Risk 4: Cost Explosion

**Risk**: 100x concurrency = 100x cost
**Impact**: Not economically viable
**Mitigation**:
- Smart task filtering (don't analyze obvious non-duplicates)
- Caching (avoid re-analyzing same pairs)
- Tiered pricing (customers pay for speed)

---

## ğŸ“¦ Deliverables

### MVP Deliverables (Week 4)

- âœ… Working orchestrator skill
- âœ… Working worker skill
- âœ… Python integration with CLI
- âœ… Performance benchmark data
- âœ… Go/No-Go recommendation document

### Production Deliverables (Week 8)

- âœ… Production-ready orchestrator (50+ workers)
- âœ… Advanced features (caching, mixed backend)
- âœ… Comprehensive documentation
- âœ… Performance tuning complete
- âœ… Release notes for v0.5.0

---

## ğŸ”— Dependencies

### Depends On
- v0.3.2 released âœ…
- Claude Code Task tool available âœ…
- Headless Claude/Opencode accessible âœ…

### Enables
- **Epic 5**: Intelligent Branch Management (uses multi-agent for duplicate detection)
- **Epic 7**: Large-scale Code Migration (analyze entire codebases in minutes)
- **Future**: Real-time code review (multi-agent parallel review)

---

## ğŸ’¡ Open Questions

### Technical Questions

1. **Max Concurrency**: What's the actual limit for Claude Task tool?
   - Need to test: 10, 20, 50, 100 workers
   - Document findings in MVP

2. **Worker Isolation**: Are workers truly parallel or serialized internally?
   - Verify with timestamps
   - Check Claude Code documentation

3. **Data Transfer**: File I/O vs embedded prompt?
   - Benchmark both approaches
   - Choose based on performance

4. **State Management**: Do workers need shared state?
   - Current design: stateless workers âœ…
   - Revisit if needed

### Business Questions

1. **Pricing Model**: Per-worker or flat fee?
   - Proposal: Tiered by max_workers (10/50/200)
   - Get customer feedback

2. **Target Customer**: SMB or Enterprise?
   - Focus: Enterprise (ä¸Šå¸‚å…¬å¸) with $$$
   - SMB can use single-agent mode

---

## ğŸ“ Next Steps

### Immediate (This Week)
1. âœ… Create Epic 6 document (this file)
2. â³ Get approval on architecture
3. â³ Create orchestrator skill template
4. â³ Start Task 6.1.1 (orchestrator foundation)

### Next Week
- Begin Week 1 development (Story 6.1)
- Daily standup to track progress
- Prototype with 2-5 workers

### Decision Point (Week 4)
- Review MVP data
- Go/No-Go on Phase 2
- Adjust Epic 5 timeline based on results

---

**Status**: ğŸ“‹ Ready for Review
**Approval Needed**: Architecture, Timeline, Budget
**Risk Level**: Medium (new technology, unproven at scale)
**Recommendation**: **Proceed with MVP** (4 weeks, low risk, high potential)

---

Generated: 2026-02-01
Epic: 6 - Multi-agent Orchestrator Infrastructure
Strategic Importance: Critical for competitive differentiation
