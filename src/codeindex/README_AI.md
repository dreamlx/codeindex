<!-- Generated by codeindex at 2026-01-27T16:47:24+08:00 -->

# README_AI.md - codeindex

## Purpose
AI-native code indexing tool that automatically generates README_AI.md files for directories using external LLM CLI tools. Includes technical debt detection capabilities for code quality analysis with multiple output formats and intelligent AI enhancement strategies for super large files.

## Architecture
The tool follows a pipeline architecture where directories are scanned, parsed, formatted into prompts, and sent to external AI CLI tools for documentation generation. It supports incremental updates, parallel processing, hierarchical organization with two-phase AI enhancement, intelligent symbol scoring for prioritization, adaptive symbol extraction with dynamic limit calculation, technical debt detection with flexible output formatting for code quality assessment, and adaptive AI enhancement strategies for handling super large files with multi-turn dialogue.

Data Flow:
```
Directory (Scanner) → Files (Scanner) → Parsed Data (Parser) → 
Symbol Scoring (SymbolImportanceScorer) → Adaptive Symbol Selection (AdaptiveSymbolSelector) → 
Technical Debt Analysis (TechDebtDetector) → 
Report Formatting (ReportFormatter) → Output (Console/Markdown/JSON) → 
Super Large File Detection (AIEnhancement) → Strategy Selection → 
Prompt (Writer) → AI CLI (Invoker) → README_AI.md (Writer)
```

## Key Components

### Core Classes

| Component | Role |
|-----------|------|
| `Config` | Central configuration loader handling `.codeindex.yaml` settings with adaptive symbols support |
| `Scanner` | Directory traversal and file filtering based on include/exclude patterns |
| `Parser` | Multi-language AST parser extracting symbols, imports, and docstrings; tracks file line counts |
| `ParseResult` | Data class containing parsed symbols, imports, module docstring, namespace, error info, and file_lines count |
| `Writer` | Formats parsed data into markdown README files |
| `SmartWriter` | Advanced writer with integrated `AdaptiveSymbolSelector` for dynamic symbol limit calculation |
| `AIEnhancementConfig` | Controls AI enhancement strategy, rate limiting, and super large file thresholds (5000 lines or 100 symbols) |
| `SymbolImportanceScorer` | Scores symbols by importance (0-100) for prioritized documentation using multi-dimensional analysis |
| `ScoringContext` | Framework and file type context for intelligent scoring |
| `AdaptiveSymbolsConfig` | Configuration for adaptive symbol extraction based on file size categories with defaults from `adaptive_config.py` |
| `AdaptiveSymbolSelector` | Dynamic symbol limit calculator implementing tiered file size-based selection algorithm |
| `SymbolsConfig` | Symbol extraction settings with integrated adaptive configuration |
| `IndexingConfig` | Top-level indexing configuration with YAML loading and validation |
| `TechDebtDetector` | Analyzes code for technical debt issues including file size, God Classes, symbol overload, and quality metrics |
| `DebtIssue` | Represents a detected technical debt issue with severity, category, metrics, and suggestions |
| `DebtAnalysisResult` | Container for technical debt analysis results including issues list and quality score |
| `DebtSeverity` | Enumeration of severity levels (CRITICAL, HIGH, MEDIUM, LOW) |
| `SymbolOverloadAnalysis` | Detailed analysis of symbol overload in files (method count, overloaded symbols, God Class detection) |
| `FileReport` | Report for a single file's technical debt analysis with aggregated issue count |
| `TechDebtReport` | Aggregate report for technical debt across multiple files with overall statistics |
| `TechDebtReporter` | Reporter for aggregating technical debt analysis across multiple files and generating aggregate reports |
| `ReportFormatter` | Abstract base class for report formatters providing format() interface |
| `ConsoleFormatter` | Human-readable console output with ANSI colors for severity levels (RED: CRITICAL, YELLOW: HIGH) |
| `MarkdownFormatter` | Markdown format with tables organized by severity level (CRITICAL, HIGH, MEDIUM, LOW) including file, category, description, and suggestion columns |
| `JSONFormatter` | Machine-readable JSON format with complete report data including file reports, issues, and metrics |
| `SuperLargeFileDetection` | Detection result for super large files with reason, recommended strategy, file lines, and symbol count |

### Command Pipeline

| Function | Command | Description |
|----------|---------|-------------|
| `scan` | `codeindex scan <path>` | Scan single directory and generate README |
| `scan-all` | `codeindex scan-all [--ai-all]` | Process all directories with two-phase strategy |
| `status` | `codeindex status` | Show indexing coverage and statistics |
| `tech_debt` | `codeindex tech-debt <path> [--format] [--output] [--recursive]` | Analyze technical debt in directory with configurable output format |

### Helper Functions

| Function | Purpose |
|----------|---------|
| `_find_python_files` | Find Python files in directory with optional recursive search; returns list of Path objects |
| `_analyze_files` | Parse and analyze Python files for technical debt; integrates parser, scorer, and detector; adds results to reporter |
| `_format_and_output` | Format technical debt report using selected formatter (console/markdown/json); write to file or stdout |
| `is_super_large_file` | Detect if file exceeds super large thresholds (>5000 lines OR >100 symbols) and return detection result with recommended strategy |
| `select_enhancement_strategy` | Select appropriate AI enhancement strategy based on file size: standard (<2000 lines, <40 symbols), hierarchical (2000-5000 lines, 40-100 symbols), or multi_turn (>5000 lines OR >100 symbols) |

### Smart Features

| Feature | Implementation |
|---------|----------------|
| Two-Phase Processing | Phase 1: SmartWriter parallel generation; Phase 2: AI enhancement with rate limiting |
| AI Enhancement Strategies | Selective (overview + oversize) or all directories with `--ai-all` |
| Incremental Updates | Git change analysis via `incremental.py` |
| Parallel Processing | Batch processing with worker pools; error results include file_lines=0 |
| Hierarchical Levels | Smart content generation based on directory depth |
| Framework Detection | Pattern recognition for PHP/ThinkPHP projects |
| Symbol Importance Scoring | Multi-dimensional scoring combining visibility (0-20pts), semantic importance (5-25pts), documentation quality (0-15pts), code complexity (5-20pts), and naming pattern analysis (-20-0pts). Theoretical range -10 to 100, clamped to 0-100. |
| Adaptive Symbol Extraction | Three-step algorithm: (1) determine file size category based on line count from `ParseResult.file_lines`, (2) get configured symbol limit for category, (3) apply constraints (min/max bounds, total available symbols). Dynamically adjusts symbol display count across 7 categories (tiny/small/medium/large/xlarge/huge/mega) with intelligent constraint resolution. |
| Configuration Merging | User-provided adaptive config merged with defaults, preserving backward compatibility |
| Truncation Message Accuracy | Truncation notice correctly compares shown symbols against filtered symbol count (after filtering), not raw symbol count |
| Technical Debt Detection | Automated detection of file size issues (>2000 lines: HIGH, >5000 lines: CRITICAL), God Class anti-pattern (>50 methods: CRITICAL), symbol overload analysis (method counting, overloaded symbol detection), and code quality scoring (0-100 scale with severity-based deductions: CRITICAL -30pts, HIGH -15pts, MEDIUM -5pts, LOW -2pts) |
| Multi-File Aggregation | `TechDebtReporter` collects file-level results and generates aggregate statistics (total files, total issues, severity breakdown, average quality score) |
| Multi-Format Output | Three formatter implementations: `ConsoleFormatter` with ANSI color codes for terminal display, `MarkdownFormatter` with severity-grouped tables for documentation, `JSONFormatter` with complete data structure for programmatic consumption |
| Recursive Debt Analysis | `tech-debt` command supports `--recursive` flag to scan subdirectories and analyze all Python files in directory tree |
| Modular Command Structure | Technical debt command refactored into focused helper functions for file discovery, analysis pipeline, and output formatting; improves testability and maintainability |
| Code Quality Standards | All CLI output messages comply with E501 line length limits (≤88 characters); long strings split across multiple lines for improved readability and linting compliance |
| Super Large File Detection | Intelligent detection of super large files based on configurable thresholds: >5000 lines (default) or >100 symbols (default). Returns detection result with reason ("excessive_lines", "excessive_symbols", or combination), recommended strategy, and file metrics. |
| Dynamic Strategy Selection | Three-tier AI enhancement strategy selection: (1) standard for normal files (<2000 lines, <40 symbols), (2) hierarchical for large files (2000-5000 lines, 40-100 symbols), (3) multi_turn for super large files (>5000 lines OR >100 symbols). Configurable thresholds in `AIEnhancementConfig`. |

## Consumes

| Module | Purpose |
|--------|---------|
| tree_sitter | Multi-language AST parsing |
| click | CLI interface and command handling |
| yaml | Configuration file parsing |
| rich | Terminal output formatting |
| git | Version control integration for incremental updates |
| json | JSON serialization for JSONFormatter |
| abc | Abstract base class for ReportFormatter interface |
| dataclasses | Data class decorators for SuperLargeFileDetection |
| typing | Type hints for Literal (EnhancementStrategy type) |
| `codeindex.adaptive_config` | Default adaptive symbols configuration and data structures |
| `codeindex.adaptive_selector` | `AdaptiveSymbolSelector` for dynamic symbol limit calculation |
| `codeindex.parser` | `ParseResult` for technical debt analysis and super large file detection; `parse_file()` for file parsing in tech-debt command |
| `codeindex.symbol_scorer` | `SymbolImportanceScorer`, `ScoringContext` for quality analysis in debt detection |
| `codeindex.tech_debt` | `TechDebtDetector`, `TechDebtReporter`, `TechDebtReport`, `DebtSeverity` data models for analysis and reporting |
| `codeindex.tech_debt_formatters` | `ConsoleFormatter`, `MarkdownFormatter`, `JSONFormatter` for report output |
| `codeindex.directory_tree` | `DirectoryTree` for directory structure operations |
| `codeindex.symbol_index` | `GlobalSymbolIndex` for cross-reference generation |
| `codeindex.smart_writer` | `SmartWriter` for intelligent README generation |
| `codeindex.config` | `Config` and `AIEnhancementConfig` for super large file thresholds |

## Provides

| Export | Usage |
|--------|-------|
| CLI Commands | `codeindex scan`, `scan-all`, `status`, `symbols`, `tech-debt` |
| README Generation | Automated documentation for code directories |
| Symbol Indexing | Global symbol cross-reference (`PROJECT_SYMBOLS.md`) |
| Incremental Updates | Smart regeneration based on changes |
| AI Enhancement | Configurable AI enhancement with rate limiting and adaptive strategies |
| File Line Tracking | `ParseResult.file_lines` provides accurate line count for each parsed file, enabling adaptive symbol selection |
| Symbol Scoring | Integrated multi-dimensional importance scoring: **Visibility** (public/protected/private patterns, language-specific rules: 0-20pts); **Semantic Analysis** (critical operations like create/update/delete/pay: 25pts, query operations like find/search: 15pts, generic methods: 5pts); **Documentation Quality** (comprehensive >200 chars: 15pts, medium >50 chars: 10pts, brief: 5pts, none: 0pts); **Code Complexity** (very large >100 lines: 20pts, large 50-100 lines: 15pts, medium 20-50 lines: 10pts, small <20 lines: 5pts); **Naming Pattern Penalties** (magic methods `__*`: -20pts, private methods `_*`: -15pts, getter/setter/checker patterns `get*/set*/is*/has*`: -10pts) |
| Adaptive Symbol Selection | `SmartWriter` integrates `AdaptiveSymbolSelector` to dynamically calculate per-file symbol limits. When `adaptive_symbols.enabled=True`, calls `calculate_limit(file_lines, total_symbols)` using actual file line counts; otherwise falls back to static `max_per_file`. Categories: tiny (<100 lines/10 symbols), small (<200/15), medium (<500/30), large (<1000/50), xlarge (<2000/80), huge (<5000/120), mega (≥5000/150). Constraints: min 5 symbols, max 200 symbols, capped by total available symbols. Truncation message uses filtered symbol count for accurate remaining symbol calculation. |
| Configuration Validation | `IndexingConfig.from_dict()` validates and merges user YAML with `DEFAULT_ADAPTIVE_CONFIG`, ensuring type safety and completeness |
| Technical Debt Analysis | `TechDebtDetector.analyze_file()` evaluates code quality and returns `DebtAnalysisResult` with detected issues, quality score (0-100), and actionable suggestions. `analyze_symbol_overload()` provides detailed symbol count analysis, overloaded symbol detection, and God Class identification. Detects: super large files (>5000 lines CRITICAL), large files (>2000 lines HIGH), God Classes (>50 methods CRITICAL with split recommendations), and symbol overload issues (massive symbol count >100 symbols HIGH, high noise ratio >50% low-quality symbols MEDIUM) |
| Technical Debt Reporting | `TechDebtReporter` provides multi-file aggregation with `add_file_result()` to collect individual `FileReport` instances and `generate_report()` to produce `TechDebtReport` with aggregate statistics: total files analyzed, total issues count, severity breakdown (critical/high/medium/low), and average quality score across all files |
| Report Formatting | Abstract `ReportFormatter` interface with three implementations: (1) `ConsoleFormatter` generates ANSI-colored output with severity highlighting (RED/YELLOW), summary statistics, and issue breakdown; (2) `MarkdownFormatter` generates documentation with summary section, severity-grouped tables (File/Category/Description/Suggestion columns), and hierarchical organization; (3) `JSONFormatter` generates machine-readable output with complete report data, file reports array, issues list, and metrics preservation |
| Technical Debt CLI | `tech-debt` command provides standalone technical debt analysis with options: `--format` (console/markdown/json), `--output` (file path), `--recursive` (scan subdirectories), `--quiet` (minimal output). Refactored into modular helper functions: `_find_python_files()` for file discovery, `_analyze_files()` for parsing and detection pipeline, `_format_and_output()` for report generation. Handles empty file lists gracefully with empty report generation. |
| Linting Compliance | All console output messages formatted to comply with E501 line length rules; status messages, AI enhancement logs, and symbol indexing output split into sub-88 character segments for improved code quality and maintainability |
| Super Large File Detection | `is_super_large_file()` function analyzes `ParseResult` against configurable thresholds (default: 5000 lines or 100 symbols) and returns `SuperLargeFileDetection` with detection result, reason (excessive_lines, excessive_symbols, or combination), recommended AI enhancement strategy, and file metrics (file_lines, symbol_count) |
| AI Enhancement Strategy Selection | `select_enhancement_strategy()` function intelligently selects one of three strategies based on file size: "standard" for normal files (<2000 lines AND <40 symbols), "hierarchical" for large files (2000-5000 lines OR 40-100 symbols), "multi_turn" for super large files (>5000 lines OR >100 symbols). Supports configurable thresholds via `AIEnhancementConfig` with defaults: super_large_lines=5000, super_large_symbols=100 |
| Enhancement Strategy Types | `EnhancementStrategy` literal type defines three valid strategies: "standard" (default single-pass generation), "hierarchical" (two-phase with structure + detail), "multi_turn" (multi-round dialogue for super large files) |

---

## Recent Changes

**Commit `73a3c57`**: feat(epic3.2): implement super large file detection (Story 3.2.1)

Changed files:
- `ai_enhancement.py` (new file)
- `config.py`

Key changes:
- Added `ai_enhancement.py` module with super large file detection and strategy selection
- Implemented `SuperLargeFileDetection` dataclass with detection result, reason, strategy, and metrics
- Implemented `is_super_large_file()` function with threshold-based detection (>5000 lines OR >100 symbols)
- Implemented `select_enhancement_strategy()` function with three-tier strategy selection (standard/hierarchical/multi_turn)
- Added `EnhancementStrategy` literal type for type-safe strategy values
- Extended `AIEnhancementConfig` with `super_large_lines` (default 5000) and `super_large_symbols` (default 100) configuration fields
- Updated `AIEnhancementConfig.from_dict()` to load super large thresholds from YAML with defaults

**Commit `08ac1b0`**: fix(cli): resolve all E501 line length errors

Changed files:
- `cli.py`

Key changes:
- Split long console output messages into multiple lines to comply with E501 line length limit (≤88 characters)
- Refactored status messages in `scan()` command: extracted formatted prefix message before path display
- Refactored AI enhancement messages in `scan_all()`: split checklist summary, rate limiting config, completion statistics into multi-line assignments
- Refactored `--ai-all` option definition: split across multiple lines for readability
- Updated ThreadPoolExecutor instantiation: extracted `max_workers` variable for clarity
- Improved code maintainability while preserving all functionality

**Commit `cf3aad3`**: refactor(cli): extract tech_debt function into focused helper functions

Changed files:
- `cli.py`

Key changes:
- Extracted file discovery logic into `_find_python_files(path, recursive)` helper
- Extracted analysis pipeline into `_analyze_files(files, detector, reporter, show_progress)` helper
- Extracted output formatting into `_format_and_output(report, format, output, quiet)` helper
- Imported `TechDebtReport` type for type hints
- Reduced `tech_debt()` function complexity from 80+ lines to ~15 lines
- Improved testability and maintainability through separation of concerns
