<!-- Generated by codeindex at 2026-01-27T19:23:40+08:00 -->

# README_AI.md - codeindex

## Purpose
AI-native code indexing tool that automatically generates README_AI.md files for directories using external LLM CLI tools. Includes technical debt detection capabilities for code quality analysis with multiple output formats and intelligent AI enhancement strategies for super large files.

## Architecture
The tool follows a pipeline architecture where directories are scanned, parsed, formatted into prompts, and sent to external AI CLI tools for documentation generation. It supports incremental updates, parallel processing, hierarchical organization with two-phase AI enhancement, intelligent symbol scoring for prioritization, adaptive symbol extraction with dynamic limit calculation, technical debt detection with flexible output formatting for code quality assessment, and adaptive AI enhancement strategies for handling super large files with multi-turn dialogue.

Data Flow:
```
Directory (Scanner) → Files (Scanner) → Parsed Data (Parser) → 
Symbol Scoring (SymbolImportanceScorer) → Adaptive Symbol Selection (AdaptiveSymbolSelector) → 
Technical Debt Analysis (TechDebtDetector) → 
Report Formatting (ReportFormatter) → Output (Console/Markdown/JSON) → 
Super Large File Detection (AIEnhancement) → Strategy Selection → 
Multi-Turn Dialogue (if super large) OR Standard Prompt → 
Prompt (Writer) → AI CLI (Invoker) → README_AI.md (Writer)
```

## Key Components

### Core Classes

| Component | Role |
|-----------|------|
| `Config` | Central configuration loader handling `.codeindex.yaml` settings with adaptive symbols support |
| `Scanner` | Directory traversal and file filtering based on include/exclude patterns |
| `Parser` | Multi-language AST parser extracting symbols, imports, and docstrings; tracks file line counts |
| `ParseResult` | Data class containing parsed symbols, imports, module docstring, namespace, error info, and file_lines count |
| `Writer` | Formats parsed data into markdown README files |
| `SmartWriter` | Advanced writer with integrated `AdaptiveSymbolSelector` for dynamic symbol limit calculation |
| `AIEnhancementConfig` | Controls AI enhancement strategy, rate limiting, and super large file thresholds (5000 lines or 100 symbols) |
| `SymbolImportanceScorer` | Scores symbols by importance (0-100) for prioritized documentation using multi-dimensional analysis |
| `ScoringContext` | Framework and file type context for intelligent scoring |
| `AdaptiveSymbolsConfig` | Configuration for adaptive symbol extraction based on file size categories with defaults from `adaptive_config.py` |
| `AdaptiveSymbolSelector` | Dynamic symbol limit calculator implementing tiered file size-based selection algorithm |
| `SymbolsConfig` | Symbol extraction settings with integrated adaptive configuration |
| `IndexingConfig` | Top-level indexing configuration with YAML loading and validation |
| `TechDebtDetector` | Analyzes code for technical debt issues including file size, God Classes, symbol overload, and quality metrics; uses unified `FileSizeClassifier` for consistent file size detection (Epic 4 refactoring) |
| `DebtIssue` | Represents a detected technical debt issue with severity, category, metrics, and suggestions |
| `DebtAnalysisResult` | Container for technical debt analysis results including issues list and quality score |
| `DebtSeverity` | Enumeration of severity levels (CRITICAL, HIGH, MEDIUM, LOW) |
| `SymbolOverloadAnalysis` | Detailed analysis of symbol overload in files (method count, overloaded symbols, God Class detection) |
| `FileReport` | Report for a single file's technical debt analysis with aggregated issue count |
| `TechDebtReport` | Aggregate report for technical debt across multiple files with overall statistics |
| `TechDebtReporter` | Reporter for aggregating technical debt analysis across multiple files and generating aggregate reports |
| `ReportFormatter` | Abstract base class for report formatters providing format() interface |
| `ConsoleFormatter` | Human-readable console output with ANSI colors for severity levels (RED: CRITICAL, YELLOW: HIGH) |
| `MarkdownFormatter` | Markdown format with tables organized by severity level (CRITICAL, HIGH, MEDIUM, LOW) including file, category, description, and suggestion columns |
| `JSONFormatter` | Machine-readable JSON format with complete report data including file reports, issues, and metrics |
| `SuperLargeFileDetection` | Detection result for super large files with reason, recommended strategy, file lines, and symbol count |
| `MultiTurnResult` | Result container for multi-turn dialogue enhancement with success status, final README content, round results, total time, and error information |
| `FileSizeClassifier` | Unified file size classification providing consistent categorization (SMALL, MEDIUM, LARGE, SUPER_LARGE) across all modules (Epic 4 Story 4.2) |
| `FileSizeCategory` | Enumeration of file size categories used by `FileSizeClassifier` |
| `FileSizeAnalysis` | Analysis result from `FileSizeClassifier` containing category, reason, file_lines, and symbol_count |

### Command Pipeline

| Function | Command | Description |
|----------|---------|-------------|
| `scan` | `codeindex scan <path>` | Scan single directory and generate README with optional `--strategy` selection (auto/standard/multi_turn) |
| `scan-all` | `codeindex scan-all [--ai-all]` | Process all directories with two-phase strategy and automatic multi-turn detection |
| `status` | `codeindex status` | Show indexing coverage and statistics |
| `tech_debt` | `codeindex tech-debt <path> [--format] [--output] [--recursive]` | Analyze technical debt in directory with configurable output format |

### Helper Functions

| Function | Purpose |
|----------|---------|
| `_find_python_files` | Find Python files in directory with optional recursive search; returns list of Path objects |
| `_analyze_files` | Parse and analyze Python files for technical debt; integrates parser, scorer, and detector; adds results to reporter |
| `_format_and_output` | Format technical debt report using selected formatter (console/markdown/json); write to file or stdout |
| `is_super_large_file` | Detect if file exceeds super large thresholds using unified `FileSizeClassifier` (Epic 4 refactoring); returns detection result with recommended strategy based on `FileSizeCategory` |
| `select_enhancement_strategy` | Select appropriate AI enhancement strategy based on file size: standard (<2000 lines, <40 symbols), hierarchical (2000-5000 lines, 40-100 symbols), or multi_turn (>5000 lines OR >100 symbols) |
| `multi_turn_ai_enhancement` | Execute 3-round multi-turn dialogue for super large files; returns `MultiTurnResult` with final README content |
| `aggregate_parse_results` | Combine multiple ParseResult objects into one aggregated result; sums file_lines and collects all symbols for multi-file directory analysis |
| `execute_multi_turn_enhancement` | Unified interface for multi-turn dialogue enhancement with auto-detection, execution, and fallback logic; eliminates code duplication between scan and scan-all commands |

### Smart Features

| Feature | Implementation |
|---------|----------------|
| Two-Phase Processing | Phase 1: SmartWriter parallel generation; Phase 2: AI enhancement with rate limiting |
| AI Enhancement Strategies | Selective (overview + oversize) or all directories with `--ai-all` |
| Incremental Updates | Git change analysis via `incremental.py` |
| Parallel Processing | Batch processing with worker pools; error results include file_lines=0 |
| Hierarchical Levels | Smart content generation based on directory depth |
| Framework Detection | Pattern recognition for PHP/ThinkPHP projects |
| Symbol Importance Scoring | Multi-dimensional scoring combining visibility (0-20pts), semantic importance (5-25pts), documentation quality (0-15pts), code complexity (5-20pts), and naming pattern analysis (-20-0pts). Theoretical range -10 to 100, clamped to 0-100. |
| Adaptive Symbol Extraction | Three-step algorithm: (1) determine file size category based on line count from `ParseResult.file_lines`, (2) get configured symbol limit for category, (3) apply constraints (min/max bounds, total available symbols). Dynamically adjusts symbol display count across 7 categories (tiny/small/medium/large/xlarge/huge/mega) with intelligent constraint resolution. |
| Configuration Merging | User-provided adaptive config merged with defaults, preserving backward compatibility |
| Truncation Message Accuracy | Truncation notice correctly compares shown symbols against filtered symbol count (after filtering), not raw symbol count |
| Technical Debt Detection | Uses unified `FileSizeClassifier` for consistent file size detection (Epic 4 refactoring); automated detection of file size issues with config-driven thresholds, God Class anti-pattern (>50 methods CRITICAL with split recommendations), and symbol overload analysis |
| Multi-File Aggregation | `TechDebtReporter` collects file-level results and generates aggregate statistics |
| Multi-Format Output | Three formatter implementations: ConsoleFormatter, MarkdownFormatter, JSONFormatter |
| Recursive Debt Analysis | `tech-debt` command supports `--recursive` flag to scan subdirectories |
| Super Large File Detection | Uses unified `FileSizeClassifier` for intelligent detection based on configurable thresholds from config (default: >5000 lines or >100 symbols) |
| Dynamic Strategy Selection | Three-tier AI enhancement strategy selection based on `FileSizeCategory`: standard (SMALL/MEDIUM), hierarchical (LARGE), or multi_turn (SUPER_LARGE) |
| Multi-Turn Dialogue Integration | CLI commands automatically detect super large files and engage multi-turn dialogue strategy with fallback to standard enhancement on failure |
| Strategy Override | `scan` command accepts `--strategy` option to manually select enhancement strategy (auto/standard/multi_turn) |
| Reusable AI Helper Functions | `ai_helper.py` module provides `aggregate_parse_results()` and `execute_multi_turn_enhancement()` to eliminate code duplication across CLI commands |
| Unified Enhancement Interface | `execute_multi_turn_enhancement()` provides single entry point handling strategy detection, execution, and fallback logic for both `scan` and `scan-all` commands |
| Unified File Size Classification | `FileSizeClassifier` provides consistent file size categorization used by both `TechDebtDetector` and `is_super_large_file()` function, eliminating duplicate threshold logic (Epic 4 Story 4.2) |

## Consumes

| Module | Purpose |
|--------|---------|
| tree_sitter | Multi-language AST parsing |
| click | CLI interface and command handling |
| yaml | Configuration file parsing |
| rich | Terminal output formatting |
| git | Version control integration for incremental updates |
| json | JSON serialization for JSONFormatter |
| abc | Abstract base class for ReportFormatter interface |
| dataclasses | Data class decorators for SuperLargeFileDetection |
| typing | Type hints for Literal (EnhancementStrategy type) |
| `codeindex.adaptive_config` | Default adaptive symbols configuration and data structures |
| `codeindex.adaptive_selector` | `AdaptiveSymbolSelector` for dynamic symbol limit calculation |
| `codeindex.parser` | `ParseResult` for technical debt analysis and super large file detection; `parse_file()` for file parsing in tech-debt command |
| `codeindex.symbol_scorer` | `SymbolImportanceScorer`, `ScoringContext` for quality analysis in debt detection |
| `codeindex.tech_debt` | `TechDebtDetector`, `TechDebtReporter`, `TechDebtReport`, `DebtSeverity` data models for analysis and reporting |
| `codeindex.tech_debt_formatters` | `ConsoleFormatter`, `MarkdownFormatter`, `JSONFormatter` for report output |
| `codeindex.directory_tree` | `DirectoryTree` for directory structure operations |
| `codeindex.symbol_index` | `GlobalSymbolIndex` for cross-reference generation |
| `codeindex.smart_writer` | `SmartWriter` for intelligent README generation |
| `codeindex.config` | `Config` and `AIEnhancementConfig` for super large file thresholds |
| `codeindex.ai_enhancement` | `is_super_large_file`, `multi_turn_ai_enhancement` for strategy detection and execution |
| `codeindex.ai_helper` | `aggregate_parse_results`, `execute_multi_turn_enhancement` for reusable AI enhancement operations |
| `codeindex.writer` | `WriteResult`, `write_readme` for README file writing |
| `codeindex.file_classifier` | `FileSizeClassifier`, `FileSizeCategory`, `FileSizeAnalysis` for unified file size classification (Epic 4 Story 4.2) |

## Provides

| Export | Usage |
|--------|-------|
| CLI Commands | `codeindex scan`, `scan-all`, `status`, `symbols`, `tech-debt` |
| README Generation | Automated documentation for code directories |
| Symbol Indexing | Global symbol cross-reference (`PROJECT_SYMBOLS.md`) |
| Incremental Updates | Smart regeneration based on changes |
| AI Enhancement | Configurable AI enhancement with rate limiting and adaptive strategies |
| File Line Tracking | `ParseResult.file_lines` provides accurate line count for each parsed file, enabling adaptive symbol selection |
| Symbol Scoring | Integrated multi-dimensional importance scoring |
| Adaptive Symbol Selection | `SmartWriter` integrates `AdaptiveSymbolSelector` to dynamically calculate per-file symbol limits |
| Configuration Validation | `IndexingConfig.from_dict()` validates and merges user YAML with defaults |
| Technical Debt Analysis | `TechDebtDetector.analyze_file()` evaluates code quality using unified `FileSizeClassifier` and returns `DebtAnalysisResult` |
| Technical Debt Reporting | `TechDebtReporter` provides multi-file aggregation |
| Report Formatting | Abstract `ReportFormatter` interface with three implementations |
| Technical Debt CLI | `tech-debt` command provides standalone technical debt analysis |
| Super Large File Detection | `is_super_large_file()` function uses unified `FileSizeClassifier` for consistent detection against configurable thresholds |
| AI Enhancement Strategy Selection | `select_enhancement_strategy()` function intelligently selects one of three strategies |
| Enhancement Strategy Types | `EnhancementStrategy` literal type defines three valid strategies |
| Multi-Turn Dialogue CLI Integration | `scan` command supports `--strategy` option with choices: auto (detect and select), standard (single prompt), multi_turn (3-round dialogue) |
| Automatic Strategy Detection | When `--strategy=auto` (default), CLI aggregates parse results and uses `is_super_large_file()` to detect super large files, automatically engaging multi-turn dialogue |
| Multi-Turn Fallback Handling | If multi-turn dialogue fails, CLI gracefully falls back to standard enhancement with user notification |
| Scan-All Multi-Turn Support | `scan-all` command automatically detects super large directories and applies multi-turn dialogue during Phase 2 AI enhancement |
| Parse Result Aggregation | `aggregate_parse_results()` combines multiple ParseResult objects for multi-file directory analysis |
| Unified Multi-Turn Enhancement | `execute_multi_turn_enhancement()` provides single entry point for multi-turn dialogue with auto-detection, strategy selection, execution, and fallback handling |
| Unified File Size Classification | `FileSizeClassifier` provides consistent categorization (SMALL, MEDIUM, LARGE, SUPER_LARGE) used across `TechDebtDetector` and `ai_enhancement` module |

---

## Recent Changes

**Commit `da32693`**: refactor(epic4): integrate FileSizeClassifier into tech_debt and ai_enhancement (Story 4.2 Tasks 4.2.3-4.2.4)

Changed files:
- `ai_enhancement.py`
- `tech_debt.py`

Key changes:
- Refactored `is_super_large_file()` in `ai_enhancement.py` to use unified `FileSizeClassifier` instead of manual threshold checks
- Strategy selection now based on `FileSizeCategory` enum: SUPER_LARGE → multi_turn, LARGE → hierarchical, others → standard
- Detection result fields (`reason`, `file_lines`, `symbol_count`) now sourced from `FileSizeAnalysis` object
- Refactored `TechDebtDetector` in `tech_debt.py` to use unified `FileSizeClassifier`
- Removed hardcoded `SUPER_LARGE_FILE` and `LARGE_FILE` class constants from `TechDebtDetector`
- Added `classifier` attribute to `TechDebtDetector` initialized with `FileSizeClassifier(config)`
- `_detect_file_size_issues()` now uses `FileSizeCategory` enum for severity mapping
- File size thresholds now config-driven via `config.ai_enhancement.super_large_lines` instead of hardcoded values
- Eliminates duplicate threshold logic across modules, ensuring consistent file size classification

**Commit `1d7fff0`**: feat(epic4): implement unified file size classifier (Story 4.2 Tasks 4.2.1-4.2.2)

Changed files:
- `file_classifier.py`

Key changes:
- Added new `file_classifier.py` module providing unified file size classification
- Implemented `FileSizeCategory` enum with four categories: SMALL, MEDIUM, LARGE, SUPER_LARGE
- Implemented `FileSizeAnalysis` dataclass containing category, reason, file_lines, and symbol_count
- Implemented `FileSizeClassifier` class with config-driven thresholds
- Classifier uses config values for super_large thresholds (lines and symbols) with fallback defaults
- Provides consistent classification logic for use across `TechDebtDetector` and `ai_enhancement` modules

**Commit `ccecd58`**: refactor(epic4): use ai_helper in scan and scan-all commands (Story 4.1 Tasks 4.1.4-4.1.5)

Changed files:
- `cli.py`

Key changes:
- Refactored `scan` command to use `execute_multi_turn_enhancement()` from `ai_helper.py` instead of inline multi-turn logic
- Removed ~50 lines of duplicated code from `scan` command including manual parse result aggregation and strategy detection
- Refactored `scan-all` command to use `execute_multi_turn_enhancement()` for super large file handling
- Removed ~30 lines of duplicated code from `scan-all` command
- Both commands now delegate to unified `execute_multi_turn_enhancement()` which handles: strategy detection (auto mode), multi-turn execution, fallback logic, and result formatting
- Simplified error handling: "not applicable" messages are now suppressed (not shown as warnings)
- Consistent return tuple handling: `(success, write_result, message)` from `execute_multi_turn_enhancement()`
- `scan-all` passes `quiet=True` to `execute_multi_turn_enhancement()` as it handles its own output formatting
